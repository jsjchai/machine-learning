## 文本相似度
### 基于统计的方式
> 基于计数方式的目标就是从语料库中自动高效地提取本质
#### 单词的分布式表示
> 构建一个密集向量（Dense Vector）来表征一个词汇,密集向量指向量的各个元素（大多数）是由非0实数表示的
#### 分布式假设
> 某个单词的含义由它周围的单词形成。单词本身没有含义，单词的含义由它所在的上下文（语境）形成
#### 共现矩阵
* you say goodbye and I say hello.

| | you  |say  |goodbye|and|I|hello|.|
|  :----:  | :----:  | :----:  | :----:  | :----:  | :----:  | :----:  | :----:  |
| you|0| 1|0|0|0|0|0|
| say| 1| 0|1|0|1|1|0|
|goodbye|0|1|0|1|0|0|0|
|and|0|0|1|0|1|0|0|
|I |0|1|0|1|0|0|0|
|hello |0|1|0|0|0|0|1|
|. |0|0|0|0|0|1|0|

#### 向量间的相似度
* 余弦相似度 
> 在信息检索中，每个词项被赋予不同的维度，而一个文档由一个向量表示，其各个维度上的值对应于该词项在文档中出现的频率。余弦相似度因此可以给出两篇文档在其主题方面的相似度
![image](https://user-images.githubusercontent.com/13389058/155826597-bde412bf-41b2-402b-b980-5fc7fe9eadfe.png)


#### 点互信息PMI
![image](https://user-images.githubusercontent.com/13389058/155826614-e02cb53a-5d2c-46ba-b78f-6098311611e8.png)
* 当两个单词的共现次数为0时,log<sub>2</sub>0=-∞,实际当中会使用正的点互信息PPMI
#### 正的点互信息PPMI
* PPMI(x,y)=max(0,PMI(x,y))


### word2vec

